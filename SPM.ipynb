{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sentencepiece as spm\n",
    "\n",
    "import smart_open as sm\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path='data/news.txt.gz'):\n",
    "    with sm.open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            cat, headline, text = line.strip().split('\\t')\n",
    "            yield cat, headline, text\n",
    "            \n",
    "        \n",
    "def tokenize_text(text):\n",
    "    text = text.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return words\n",
    "\n",
    "def normalize_text(text):\n",
    "    return ' '.join(tokenize_text(text))\n",
    "\n",
    "def prepare_spm_file(f_out, data):\n",
    "    with open(f_out, 'w', encoding='utf-8') as f:\n",
    "        for cat, headline, text in tqdm_notebook(data):\n",
    "            f.write(normalize_text(headline))\n",
    "            f.write('\\n')\n",
    "            \n",
    "            sents = (sent for sent in re.split(r'[.!?]', text) if len(sent) > 20)\n",
    "    \n",
    "            for sent in sents:\n",
    "                f.write(normalize_text(sent))\n",
    "                f.write('\\n')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f2677bb1574875be74bdadb117c8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_spm_file('data/spm.txt', read_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolex наградит победителей регаты\n",
      "парусная гонка giraglia rolex cup пройдет в средиземном море в 64 й раз\n",
      "победители соревнования проводимого с 1953 года yacht club italiano помимо других призов традиционно получают в подарок часы от швейцарского бренда rolex\n",
      "об этом сообщается в пресс релизе поступившем в редакцию ленты\n",
      "rolex yacht master 40 фото пресс служба mercury соревнования будут проходить с 10 по 18 июня\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/spm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train('--input=data/spm.txt \\\n",
    "                               --pad_id=0 \\\n",
    "                               --bos_id=2 \\\n",
    "                               --eos_id=3  \\\n",
    "                               --unk_id=1 \\\n",
    "                               --model_prefix=data/news_spm \\\n",
    "                               --vocab_size=5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc = spm.SentencePieceProcessor()\n",
    "proc.Load('data/news_spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁октября']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.EncodeAsPieces('октября')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sents = [proc.EncodeAsPieces(line.strip()) \n",
    "                     for line in open('data/spm.txt', encoding='utf-8')]\n",
    "w2v = Word2Vec(sents)\n",
    "\n",
    "w2v.wv.save_word2vec_format('data/w2v_vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁июля', 0.9749369025230408),\n",
       " ('▁сентября', 0.9721417427062988),\n",
       " ('▁марта', 0.969996988773346),\n",
       " ('▁декабря', 0.9690101742744446),\n",
       " ('▁августа', 0.9684216976165771),\n",
       " ('▁июня', 0.9678225517272949),\n",
       " ('▁ноября', 0.9669003486633301),\n",
       " ('▁февраля', 0.9666882753372192),\n",
       " ('▁апреля', 0.9643102884292603),\n",
       " ('▁мая', 0.9626060128211975)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(proc.EncodeAsPieces('октября'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = w2v.wv.vector_size\n",
    "\n",
    "def _piece_id_to_vect(piece_id):\n",
    "    piece = proc.id_to_piece(piece_id) \n",
    "    if piece in w2v.wv:\n",
    "        return w2v.wv[piece]\n",
    "    return np.zeros((emb_size,))\n",
    "\n",
    "emb = np.array([_piece_id_to_vect(piece_id) for piece_id in range(0, len(proc))])\n",
    "np.save('data/vectors.npy', emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁при', 'вет', '▁мир']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.EncodeAsPieces(normalize_text('привет мир'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted({label for (label, _, _) in read_data()})\n",
    "label_to_idx = {label:idx for (idx, label) in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 120\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = normalize_text(text)\n",
    "    pieces = proc.EncodeAsIds(text)\n",
    "    if len(pieces) > max_seq_len:\n",
    "        pieces = pieces[:max_seq_len]\n",
    "    to_add = (max_seq_len - len(pieces))\n",
    "    pieces = pieces + to_add * [proc.pad_id()]\n",
    "    \n",
    "    return np.array(pieces)\n",
    "    \n",
    "\n",
    "def prepare_data(label_to_idx):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label, headline, text in read_data():\n",
    "        label_id = label_to_idx[label]\n",
    "        X.append(prepare_text(headline + ' ' + text))\n",
    "        y.append(label_id)\n",
    "       \n",
    "    return np.array(X), np.array(y)\n",
    "    \n",
    "X, y = prepare_data(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2508,  0.1793,  0.2189,  ..., -1.1806,  2.7978, -0.2542],\n",
       "        [-1.0755,  0.7262,  0.5747,  ..., -0.4297,  0.7703,  0.1982],\n",
       "        [ 0.4433,  0.6389, -0.5718,  ..., -0.0887,  0.7056, -0.2806],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer = nn.Embedding.from_pretrained(torch.tensor(emb), padding_idx=proc.pad_id())\n",
    "emb_layer(torch.tensor(prepare_text('привет мир')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.LongTensor(X)\n",
    "y = torch.LongTensor(y)\n",
    "\n",
    "l = X.size(0)\n",
    "l_train, l_test = int(l * 0.7), int(l * 0.2)\n",
    "\n",
    "data = TensorDataset(X, y)\n",
    "train_ds, test_ds, val_ds = random_split(data, [l_train, l_test, l - l_train - l_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.EmbeddingBag.from_pretrained(torch.FloatTensor(emb)),\n",
    "                      nn.Linear(emb.shape[1], 20),\n",
    "                      #nn.ReLU(),\n",
    "                      #nn.Dropout(0.2),\n",
    "                      nn.Linear(20, len(labels)),\n",
    "                      nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, acc = 0.46157, loss = 1.9048439264297485\n",
      "Epoch = 10, acc = 0.64229, loss = 1.7881412506103516\n",
      "Epoch = 20, acc = 0.65129, loss = 1.7816226482391357\n",
      "Epoch = 30, acc = 0.66000, loss = 1.7215139865875244\n",
      "Epoch = 40, acc = 0.66343, loss = 1.7081806659698486\n",
      "Epoch = 50, acc = 0.65986, loss = 1.6618688106536865\n",
      "Epoch = 60, acc = 0.66571, loss = 1.6168361902236938\n",
      "Epoch = 70, acc = 0.66300, loss = 1.5674864053726196\n",
      "Epoch = 80, acc = 0.66086, loss = 1.663656234741211\n",
      "Epoch = 90, acc = 0.67014, loss = 1.736398696899414\n",
      "Epoch = 100, acc = 0.66729, loss = 1.5614030361175537\n",
      "Epoch = 110, acc = 0.67100, loss = 1.5611494779586792\n",
      "Epoch = 120, acc = 0.66729, loss = 1.561150312423706\n",
      "Epoch = 130, acc = 0.67286, loss = 1.5692418813705444\n",
      "Epoch = 140, acc = 0.66514, loss = 1.5646708011627197\n",
      "Epoch = 150, acc = 0.67557, loss = 1.561161994934082\n",
      "Epoch = 160, acc = 0.67186, loss = 1.5611525774002075\n",
      "Epoch = 170, acc = 0.66986, loss = 1.5611501932144165\n",
      "Epoch = 180, acc = 0.67357, loss = 1.5617300271987915\n",
      "Epoch = 190, acc = 0.67957, loss = 1.5698127746582031\n",
      "Epoch = 200, acc = 0.67571, loss = 1.7058162689208984\n",
      "Epoch = 210, acc = 0.68086, loss = 1.5611661672592163\n",
      "Epoch = 220, acc = 0.65814, loss = 1.5611501932144165\n",
      "Epoch = 230, acc = 0.67186, loss = 1.5611501932144165\n",
      "Epoch = 240, acc = 0.67829, loss = 1.561150312423706\n",
      "Epoch = 250, acc = 0.67257, loss = 1.5611501932144165\n",
      "Epoch = 260, acc = 0.66429, loss = 1.5611501932144165\n",
      "Epoch = 270, acc = 0.66000, loss = 1.5611501932144165\n",
      "Epoch = 280, acc = 0.67871, loss = 1.661151647567749\n",
      "Epoch = 290, acc = 0.67186, loss = 1.6074718236923218\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train, val, test, max_epochs=300):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_loader = DataLoader(dataset=train_ds, batch_size=30)\n",
    "    val_loader = DataLoader(dataset=val_ds)\n",
    "    test_loader = DataLoader(dataset=test_ds)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        cur = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:   \n",
    "            model.train()\n",
    "            y_pred = model(X_batch)    \n",
    "            bce = loss(y_pred, y_batch)\n",
    "                        \n",
    "            bce.backward()        \n",
    "\n",
    "            cur += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()       \n",
    "           \n",
    "        if epoch % 10 == 0:        \n",
    "            acc = cur / total\n",
    "            print(f'Epoch = {epoch}, acc = {acc:.5f}, loss = {bce}')   \n",
    "\n",
    "train_model(model, train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
